{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3342171,"sourceType":"datasetVersion","datasetId":2017696},{"sourceId":11075445,"sourceType":"datasetVersion","datasetId":6902500},{"sourceId":11129639,"sourceType":"datasetVersion","datasetId":6941193},{"sourceId":11129916,"sourceType":"datasetVersion","datasetId":6941397},{"sourceId":11130055,"sourceType":"datasetVersion","datasetId":6941498},{"sourceId":11132404,"sourceType":"datasetVersion","datasetId":6943089},{"sourceId":11132424,"sourceType":"datasetVersion","datasetId":6943103},{"sourceId":291902,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":250052,"modelId":271546},{"sourceId":296883,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":254106,"modelId":275525},{"sourceId":297604,"sourceType":"modelInstanceVersion","modelInstanceId":254611,"modelId":276003},{"sourceId":298468,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":255266,"modelId":276633}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport imageio.v2 as imageio  # Use imageio.v2 to avoid deprecation warnings\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Paths\nHR_DIR = \"/kaggle/input/lsdir33/0003000\"  # High-resolution images\nNOISY_DIR = \"/kaggle/working/lsdir33/noise\"  # Output directory for noisy images\n\n# Ensure output directory exists\nos.makedirs(NOISY_DIR, exist_ok=True)\n\nimport cupy as cp\n\ndef add_noise(image, sigma=50):\n    image = cp.array(image / 255, dtype=cp.float32)\n    noise = cp.random.normal(0, sigma / 255, image.shape)\n    gauss_noise = image + noise\n    return (gauss_noise * 255).get()  # Convert back to NumPy\n\ndef save_image(image, path):\n    \"\"\"\n    Saves an image after clipping and rounding to uint8 format.\n    image: Image as numpy array.\n    path: Save location.\n    \"\"\"\n    image = np.round(np.clip(image, 0, 255)).astype(np.uint8)\n    imageio.imwrite(path, image)\n\ndef crop_image(image, s=8):\n    \"\"\"\n    Crops an image so its width & height are multiples of 's'.\n    \"\"\"\n    h, w, c = image.shape\n    image = image[:h - h % s, :w - w % s, :]\n    return image\n\n# Process all images in the HR directory\nfor img_name in os.listdir(HR_DIR):\n    if img_name.endswith(\".png\"):  # Process only PNG files\n        img_path = os.path.join(HR_DIR, img_name)\n        noisy_img_path = os.path.join(NOISY_DIR, img_name)\n\n        # Read and process the image\n        img = imageio.imread(img_path)\n        img = crop_image(img)  # Ensure size is multiple of 8\n        img_noise = add_noise(img, sigma=50)  # Add noise\n\n        # Save the noisy image\n        save_image(img_noise, noisy_img_path)\n        print(f\"Processed: {img_name}\")\n\nprint(\"All images processed and saved in\", NOISY_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T05:43:10.958514Z","iopub.execute_input":"2025-03-23T05:43:10.958785Z","iopub.status.idle":"2025-03-23T05:48:49.344870Z","shell.execute_reply.started":"2025-03-23T05:43:10.958767Z","shell.execute_reply":"2025-03-23T05:48:49.344155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\n\n# ✅ Custom Dataset Class (Handles Clean & Noisy Images)\nclass DenoiseDataset(Dataset):\n    def __init__(self, clean_dir, noisy_dir, transform=None):\n        self.clean_images = sorted(os.listdir(clean_dir))\n        self.noisy_images = sorted(os.listdir(noisy_dir))\n        self.clean_dir = clean_dir\n        self.noisy_dir = noisy_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.clean_images)\n\n    def __getitem__(self, idx):\n        clean_path = os.path.join(self.clean_dir, self.clean_images[idx])\n        noisy_path = os.path.join(self.noisy_dir, self.noisy_images[idx])\n\n        # Load images using OpenCV (NumPy arrays)\n        clean_img = cv2.imread(clean_path)\n        noisy_img = cv2.imread(noisy_path)\n\n        # Convert BGR to RGB\n        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n\n        # Convert NumPy array to PIL Image\n        clean_img = Image.fromarray(clean_img)\n        noisy_img = Image.fromarray(noisy_img)\n\n        # Apply transformations\n        if self.transform:\n            clean_img = self.transform(clean_img)\n            noisy_img = self.transform(noisy_img)\n\n        return noisy_img, clean_img\n\n# ✅ Data Augmentation & Transformations\ntransform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor()  # Convert to PyTorch tensor\n])\n\n# ✅ Define dataset paths (for 4 datasets)\ndataset_paths = [\n    (\"/kaggle/input/div2k-high-resolution-images/DIV2K_train_HR/DIV2K_train_HR\", \"/kaggle/input/noisyd/noisy_data/DIV2K/DIV2K_train_HR/DIV2K_train_HR\"),\n    (\"/kaggle/input/lsdier22/0002000\", \"/kaggle/working/lsdir22/noise\"),\n    (\"/kaggle/input/lsdir11/0001000\", \"/kaggle/working/lsdir11/noise\"),\n    (\"/kaggle/input/lsdir33/0003000\", \"/kaggle/working/lsdir33/noise\"),\n    (\"/kaggle/input/lsdir44/0004000\", \"/kaggle/working/lsdir44/noise\"),\n    (\"/kaggle/input/lsdir55/0005000\", \"/kaggle/working/lsdir55/noise\")\n]\n\n# ✅ Create datasets for all 6 datasets\ndatasets = [DenoiseDataset(clean, noisy, transform) for clean, noisy in dataset_paths]\n\n# ✅ Combine datasets into one\ncombined_dataset = ConcatDataset(datasets)\n\n# ✅ Create DataLoader\ntrain_loader = DataLoader(combined_dataset, batch_size=4, shuffle=True, num_workers=4)\n\nprint(f\"Total images in combined dataset: {len(combined_dataset)}\")\nprint(\"✅ DataLoader ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T16:59:27.989911Z","iopub.execute_input":"2025-03-23T16:59:27.990343Z","iopub.status.idle":"2025-03-23T16:59:28.103968Z","shell.execute_reply.started":"2025-03-23T16:59:27.990306Z","shell.execute_reply":"2025-03-23T16:59:28.103175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):\n        super(UNet, self).__init__()\n        \n        # Encoder\n        self.encoders = nn.ModuleList()\n        for feature in features:\n            self.encoders.append(self._conv_block(in_channels, feature))\n            in_channels = feature\n        \n        # Bottleneck\n        self.bottleneck = self._conv_block(features[-1], features[-1] * 2)\n        \n        # Decoder\n        self.decoders = nn.ModuleList()\n        for feature in reversed(features):\n            self.decoders.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n            self.decoders.append(self._conv_block(feature * 2, feature))\n        \n        # Final Output Layer\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def _conv_block(self, in_channels, out_channels):\n        \"\"\"Double Convolution Block\"\"\"\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        skip_connections = []\n        for encoder in self.encoders:\n            x = encoder(x)\n            skip_connections.append(x)\n            x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        x = self.bottleneck(x)\n\n        skip_connections = skip_connections[::-1]\n        for i in range(0, len(self.decoders), 2):\n            x = self.decoders[i](x)  # Upconvolution\n            skip_connection = skip_connections[i // 2]\n\n            if x.shape != skip_connection.shape:\n                x = F.interpolate(x, size=skip_connection.shape[2:], mode=\"bilinear\", align_corners=True)\n\n            x = torch.cat((skip_connection, x), dim=1)  # Skip connection\n            x = self.decoders[i + 1](x)  # Convolution Block\n\n        return self.final_conv(x)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Charbonnier Loss (L1-like but robust)\nclass CharbonnierLoss(nn.Module):\n    def __init__(self, epsilon=1e-3):\n        super(CharbonnierLoss, self).__init__()\n        self.epsilon = epsilon\n\n    def forward(self, pred, target):\n        return torch.mean(torch.sqrt((pred - target) ** 2 + self.epsilon ** 2))\n\n# SSIM Loss\ndef ssim_loss(pred, target):\n    mu_pred = F.avg_pool2d(pred, kernel_size=3, stride=1, padding=1)\n    mu_target = F.avg_pool2d(target, kernel_size=3, stride=1, padding=1)\n    sigma_pred = F.avg_pool2d(pred ** 2, kernel_size=3, stride=1, padding=1) - mu_pred ** 2\n    sigma_target = F.avg_pool2d(target ** 2, kernel_size=3, stride=1, padding=1) - mu_target ** 2\n    sigma_pred_target = F.avg_pool2d(pred * target, kernel_size=3, stride=1, padding=1) - mu_pred * mu_target\n    c1, c2 = 0.01 ** 2, 0.03 ** 2\n    ssim = ((2 * mu_pred * mu_target + c1) * (2 * sigma_pred_target + c2)) / ((mu_pred ** 2 + mu_target ** 2 + c1) * (sigma_pred + sigma_target + c2))\n    return torch.clamp((1 - ssim) / 2, 0, 1).mean()\n\n# Denoising Loss (Only Charbonnier + SSIM)\nclass DenoiseLoss(nn.Module):\n    def __init__(self):\n        super(DenoiseLoss, self).__init__()\n        self.charbonnier = CharbonnierLoss()\n        self.alpha = nn.Parameter(torch.tensor(0.5))  # Learnable weight for Charbonnier\n        self.beta = nn.Parameter(torch.tensor(0.5))   # Learnable weight for SSIM\n\n    def forward(self, pred, target):\n        l1 = self.charbonnier(pred, target)\n        ssim = ssim_loss(pred, target)\n\n        # Normalize weights dynamically\n        total_weight = self.alpha + self.beta\n        return (self.alpha / total_weight) * l1 + (self.beta / total_weight) * ssim\n\n# Initialize UNet Model (Ensure UNet class is defined before this)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(in_channels=3, out_channels=3).to(device)\n\n# Define loss function\ncriterion = DenoiseLoss().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T17:01:02.874080Z","iopub.execute_input":"2025-03-23T17:01:02.874427Z","iopub.status.idle":"2025-03-23T17:01:03.447830Z","shell.execute_reply.started":"2025-03-23T17:01:02.874396Z","shell.execute_reply":"2025-03-23T17:01:03.447026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Initialize UNet Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(in_channels=3, out_channels=3).to(device)\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\nscaler = GradScaler()  # Enable Mixed Precision Training\n\n# Define Transform with Random Cropping\ntrain_transform = transforms.Compose([\n    transforms.RandomCrop(128),\n    transforms.RandomHorizontalFlip(p=0.5),  # Flip images horizontally\n    transforms.RandomVerticalFlip(p=0.5),  # Flip images vertically (optional)\n    transforms.RandomRotation(degrees=10),  # Small rotations to introduce variance# Crop to 128x128 patches\n    transforms.ToTensor()\n])\n\n# Training Loop\nnum_epochs = 10\naccumulation_steps = 4  # Effective batch size multiplier\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    optimizer.zero_grad()\n\n    for i, (noisy_imgs, clean_imgs) in enumerate(train_loader):\n        noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n\n        with autocast():  # Enable Mixed Precision\n            outputs = model(noisy_imgs)\n            loss = criterion(outputs, clean_imgs) / accumulation_steps  # Scale loss\n\n        scaler.scale(loss).backward()  # Backpropagate scaled loss\n\n        if (i + 1) % accumulation_steps == 0:  # Update weights every 'accumulation_steps' batches\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        epoch_loss += loss.item() * accumulation_steps  # Reverse scaling\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.6f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\n\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    total_psnr = 0\n    total_ssim = 0\n    num_samples = 0\n\n    with torch.no_grad():\n        for noisy_imgs, clean_imgs in dataloader:\n            noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n            denoised_imgs = model(noisy_imgs)\n\n            for i in range(noisy_imgs.shape[0]):\n                clean_np = clean_imgs[i].cpu().numpy().transpose(1, 2, 0)  # (H, W, C)\n                denoised_np = denoised_imgs[i].cpu().numpy().transpose(1, 2, 0)\n\n                clean_np = np.clip(clean_np, 0, 1)\n                denoised_np = np.clip(denoised_np, 0, 1)\n\n                # Compute PSNR\n                img_psnr = psnr(clean_np, denoised_np, data_range=1.0)\n\n                # Compute SSIM with win_size fix\n                try:\n                    img_ssim = ssim(clean_np, denoised_np, data_range=1.0, win_size=3, channel_axis=-1)\n                except ValueError as e:\n                    print(f\"Skipping SSIM for small image: {clean_np.shape} - {e}\")\n                    img_ssim = 0  # Assign 0 if SSIM cannot be computed\n\n                total_psnr += img_psnr\n                total_ssim += img_ssim\n                num_samples += 1\n\n    avg_psnr = total_psnr / num_samples\n    avg_ssim = total_ssim / num_samples\n    print(f\"Validation PSNR: {avg_psnr:.2f} dB, SSIM: {avg_ssim:.4f}\")\n    return avg_psnr, avg_ssim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:39:09.892958Z","iopub.execute_input":"2025-03-23T19:39:09.893337Z","iopub.status.idle":"2025-03-23T19:39:10.840311Z","shell.execute_reply.started":"2025-03-23T19:39:09.893304Z","shell.execute_reply":"2025-03-23T19:39:10.839591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Val(Dataset):\n    def __init__(self, clean_dir, noisy_dir, transform=None):\n        self.clean_images = sorted(os.listdir(clean_dir))\n        self.noisy_images = sorted(os.listdir(noisy_dir))\n        self.clean_dir = clean_dir\n        self.noisy_dir = noisy_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.clean_images)\n\n    def __getitem__(self, idx):\n        clean_path = os.path.join(self.clean_dir, self.clean_images[idx])\n        noisy_path = os.path.join(self.noisy_dir, self.noisy_images[idx])\n\n        # Load images using OpenCV (NumPy arrays)\n        clean_img = cv2.imread(clean_path)\n        noisy_img = cv2.imread(noisy_path)\n\n        # Convert BGR to RGB\n        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n\n        # Convert NumPy array to PIL Image\n        clean_img = Image.fromarray(clean_img)\n        noisy_img = Image.fromarray(noisy_img)\n\n        # Apply transformations\n        if self.transform:\n            clean_img = self.transform(clean_img)\n            noisy_img = self.transform(noisy_img)\n\n        return noisy_img, clean_img\n\n# Data augmentation & transformations\ntransform = transforms.Compose([\n    transforms.Resize((512, 512)),  # Resize all images to 512x512\n    transforms.ToTensor()  # Convert to PyTorch tensor\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:39:14.286169Z","iopub.execute_input":"2025-03-23T19:39:14.286864Z","iopub.status.idle":"2025-03-23T19:39:14.294561Z","shell.execute_reply.started":"2025-03-23T19:39:14.286835Z","shell.execute_reply":"2025-03-23T19:39:14.293356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define validation dataset paths\nval_clean_dir = \"/kaggle/input/div2k-high-resolution-images/DIV2K_valid_HR/DIV2K_valid_HR\"\nval_noisy_dir = \"/kaggle/input/noisyd/noisy_data/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR\"\n\n# Create validation dataset and dataloader\nval_dataset = Val(val_clean_dir, val_noisy_dir, transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n\n# Evaluate Model\nevaluate_model(model, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:39:19.163109Z","iopub.execute_input":"2025-03-23T19:39:19.163469Z","iopub.status.idle":"2025-03-23T19:40:11.604717Z","shell.execute_reply.started":"2025-03-23T19:39:19.163436Z","shell.execute_reply":"2025-03-23T19:40:11.603652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model, \"unet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:40:24.633106Z","iopub.execute_input":"2025-03-23T19:40:24.633435Z","iopub.status.idle":"2025-03-23T19:40:24.953614Z","shell.execute_reply.started":"2025-03-23T19:40:24.633406Z","shell.execute_reply":"2025-03-23T19:40:24.952873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\n\n\nclass TestDenoiseDataset(Dataset):\n    def __init__(self, noisy_dir, transform=None):\n        self.noisy_images = sorted(os.listdir(noisy_dir))\n        self.noisy_dir = noisy_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.noisy_images)\n\n    def __getitem__(self, idx):\n        noisy_path = os.path.join(self.noisy_dir, self.noisy_images[idx])\n\n        # Load noisy image\n        noisy_img = cv2.imread(noisy_path)\n        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n        noisy_img = Image.fromarray(noisy_img)  # Convert to PIL\n\n        # Apply transformations\n        if self.transform:\n            noisy_img = self.transform(noisy_img)\n\n        return noisy_img, self.noisy_images[idx]  # Return filename for saving","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:44:53.330145Z","iopub.execute_input":"2025-03-23T19:44:53.330446Z","iopub.status.idle":"2025-03-23T19:44:57.532996Z","shell.execute_reply.started":"2025-03-23T19:44:53.330424Z","shell.execute_reply":"2025-03-23T19:44:57.532335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --fuzzy --id 1UZA_AEdV5EgqWl9lozYo12YrET-Pno6L","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:45:01.806162Z","iopub.execute_input":"2025-03-23T19:45:01.806626Z","iopub.status.idle":"2025-03-23T19:45:17.357206Z","shell.execute_reply.started":"2025-03-23T19:45:01.806546Z","shell.execute_reply":"2025-03-23T19:45:17.356070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\nzip_file = \"/kaggle/working/LSDIR_DIV2K_Test_Sigma50.zip\"\nextract_folder = \"/kaggle/working/LSDIR_DIV2K_Test_Sigma50\"\n\nshutil.unpack_archive(zip_file, extract_folder)\nos.remove(zip_file)\nprint(\"Unzipped and deleted!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:45:20.518784Z","iopub.execute_input":"2025-03-23T19:45:20.519129Z","iopub.status.idle":"2025-03-23T19:45:23.619331Z","shell.execute_reply.started":"2025-03-23T19:45:20.519099Z","shell.execute_reply":"2025-03-23T19:45:23.618350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_noisy_dir = \"/kaggle/working/LSDIR_DIV2K_Test_Sigma50\"\n\ntest_dataset = TestDenoiseDataset(test_noisy_dir, transform=transforms.ToTensor())\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:45:38.364387Z","iopub.execute_input":"2025-03-23T19:45:38.364732Z","iopub.status.idle":"2025-03-23T19:45:38.369471Z","shell.execute_reply.started":"2025-03-23T19:45:38.364704Z","shell.execute_reply":"2025-03-23T19:45:38.368642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Define Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load Full Model (Not Recommended but Works)\nmodel = torch.load(\"/kaggle/input/unet-denoise4/pytorch/default/1/unet(4)\", map_location=device)\n\n# Set Model to Evaluation Mode\nmodel.eval()\n\nprint(\"Full model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:45:41.238303Z","iopub.execute_input":"2025-03-23T19:45:41.238631Z","iopub.status.idle":"2025-03-23T19:45:44.142899Z","shell.execute_reply.started":"2025-03-23T19:45:41.238603Z","shell.execute_reply":"2025-03-23T19:45:44.142176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.transforms as transforms\n\noutput_dir = \"denoised_results1\"\nos.makedirs(output_dir, exist_ok=True)\n\nmodel.eval()\nwith torch.no_grad():\n    for noisy_imgs, filenames in test_loader:\n        noisy_imgs = noisy_imgs.to(device)\n\n        # Denoise\n        denoised_imgs = model(noisy_imgs)\n\n        # Normalize outputs to [0, 1]\n        denoised_imgs = torch.clamp(denoised_imgs, 0, 1)  # Ensure values are in [0,1]\n\n        for i in range(denoised_imgs.shape[0]):  \n            img = denoised_imgs[i].cpu().float()  # Ensure float32\n            \n            # Normalize properly\n            min_val, max_val = img.min(), img.max()\n            if max_val > min_val:  # Avoid division by zero\n                img = (img - min_val) / (max_val - min_val)\n\n            # Convert to RGB & Save\n            denoised_pil = transforms.ToPILImage()(img).convert(\"RGB\")\n            denoised_pil.save(f\"{output_dir}/{filenames[i]}\", quality=95)\n\nprint(f\"Denoised images saved in {output_dir}/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:45:48.976812Z","iopub.execute_input":"2025-03-23T19:45:48.977112Z","iopub.status.idle":"2025-03-23T19:52:56.562863Z","shell.execute_reply.started":"2025-03-23T19:45:48.977090Z","shell.execute_reply":"2025-03-23T19:52:56.562119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"denoised\", 'zip', \"/kaggle/working/denoised_results1\")  # Zips the entire folder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:53:06.241474Z","iopub.execute_input":"2025-03-23T19:53:06.241807Z","iopub.status.idle":"2025-03-23T19:53:31.366107Z","shell.execute_reply.started":"2025-03-23T19:53:06.241785Z","shell.execute_reply":"2025-03-23T19:53:31.365015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.transforms as transforms\nfrom ipywidgets import interact, IntSlider\nfrom PIL import Image\n\n# Set directories\nnoisy_dir = \"/kaggle/working/LSDIR_DIV2K_Test_Sigma50\"  # Folder with noisy test images\ndenoised_dir = \"/kaggle/working/denoised_results1\"  # Folder with saved denoised images\n\n# Load image filenames\nnoisy_images = sorted(os.listdir(noisy_dir))\ndenoised_images = sorted(os.listdir(denoised_dir))\n\n# Ensure matching images\nassert len(noisy_images) == len(denoised_images), \"Mismatch in number of images!\"\n\n# Load and preprocess images\ndef load_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    return np.array(image)\n\n# Interactive visualization\ndef show_images(index):\n    noisy_img = load_image(os.path.join(noisy_dir, noisy_images[index]))\n    denoised_img = load_image(os.path.join(denoised_dir, denoised_images[index]))\n\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    axes[0].imshow(noisy_img)\n    axes[0].set_title(\"Noisy Image\")\n    axes[0].axis(\"off\")\n\n    axes[1].imshow(denoised_img)\n    axes[1].set_title(\"Denoised Image\")\n    axes[1].axis(\"off\")\n\n    plt.show()\n\n# Create interactive slider\ninteract(show_images, index=IntSlider(0, 0, len(noisy_images) - 1, 1));","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:53:57.492318Z","iopub.execute_input":"2025-03-23T19:53:57.492690Z","iopub.status.idle":"2025-03-23T19:53:58.450039Z","shell.execute_reply.started":"2025-03-23T19:53:57.492660Z","shell.execute_reply":"2025-03-23T19:53:58.448824Z"}},"outputs":[],"execution_count":null}]}